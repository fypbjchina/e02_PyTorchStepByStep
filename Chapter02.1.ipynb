{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch Step-by-Step: A Beginner's Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2.1\n",
    "\n",
    "* env: \n",
    "    * zuv_training (Python 3.11.11)\n",
    "    * fyp2024 (Python 3.11.5) \n",
    "    * fpytorch (Python 3.11.11)\n",
    "* packages:<br>\n",
    "    %% Chapter00\n",
    "    * numpy-1.26.4: python -c \"import numpy; print(numpy.__ version__)\"\n",
    "    * scipy-1.15.1: python -c \"import scipy; print(scipy.__ version__)\"\n",
    "    * scikit-learn-1.6.1<br>\n",
    "    \n",
    "    %% Chapter01\n",
    "    * tensorboard-2.19.0 --> pip install tensorboard\n",
    "    * scikit-learn-1.6.1 --> conda install scikit-learn\n",
    "    * pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    * torchviz-0.0.3 --> print(pkg_resources.get_distribution('torchviz').version)\n",
    "    * graphviz --> install from IT Service Port\n",
    "\n",
    "    %% Chapter02 - tensorboard???\n",
    "    * tensorboard-2.19.0 --> pip install tensorboard==2.11.0\n",
    "    * numpy==1.26.4 --> pip install numpy==1.23.5\n",
    "\n",
    "     %% Chapter02.1\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    import requests\n",
    "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open('config.py', 'wb').write(r.content)    \n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "from config import *\n",
    "config_chapter2_1()\n",
    "# This is needed to render the plots in this chapter\n",
    "from plots.chapter2_1 import figure1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Classy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completely empty (and useless) class\n",
    "class StepByStep(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step_fn = self._make_train_step()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step_fn = self._make_val_step()\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_train_step_fn(self):\n",
    "    # This method does not need ARGS... it can refer to\n",
    "    # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step_fn(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = self.model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = self.loss_fn(yhat, y)\n",
    "        # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "        loss.backward()\n",
    "        # Step 4 - Updates parameters using gradients and the\n",
    "        # learning rate\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "\n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return perform_train_step_fn\n",
    "\n",
    "def _make_val_step_fn(self):\n",
    "    # Builds function that performs a step in the validation loop\n",
    "    def perform_val_step_fn(x, y):\n",
    "        # Sets model to EVAL mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = self.model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = self.loss_fn(yhat, y)\n",
    "        # There is no need to compute Steps 3 and 4, \n",
    "        # since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "\n",
    "    return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION! Using SETATTR for educational purposes only :-)\n",
    "setattr(StepByStep, '_make_train_step_fn', _make_train_step_fn)\n",
    "setattr(StepByStep, '_make_val_step_fn', _make_val_step_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `setattr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex\n"
     ]
    }
   ],
   "source": [
    "rex = Dog('Rex')\n",
    "print(rex.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bark(dog):\n",
    "    print('{} barks: \"Woof!\"'.format(dog.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "bark(rex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bark(self):\n",
    "    print('{} barks: \"Woof!\"'.format(self.name))\n",
    "\n",
    "setattr(Dog, 'bark', bark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fido barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "fido = Dog('Fido')\n",
    "fido.bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "rex.bark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mini_batch(self, validation=False):\n",
    "    # The mini-batch can be used with both loaders\n",
    "    # The argument `validation`defines which loader and \n",
    "    # corresponding step function is going to be used\n",
    "    if validation:\n",
    "        data_loader = self.val_loader\n",
    "        step_fn = self.val_step_fn\n",
    "    else:\n",
    "        data_loader = self.train_loader\n",
    "        step_fn = self.train_step_fn\n",
    "\n",
    "    if data_loader is None:\n",
    "        return None\n",
    "\n",
    "    # Once the data loader and step function, this is the same\n",
    "    # mini-batch loop we had before\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(self.device)\n",
    "        y_batch = y_batch.to(self.device)\n",
    "\n",
    "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "\n",
    "    return loss\n",
    "\n",
    "setattr(StepByStep, '_mini_batch', _mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(self, seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "setattr(StepByStep, 'set_seed', set_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, n_epochs, seed=42):\n",
    "    # To ensure reproducibility of the training process\n",
    "    self.set_seed(seed)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Keeps track of the numbers of epochs\n",
    "        # by updating the corresponding attribute\n",
    "        self.total_epochs += 1\n",
    "\n",
    "        # inner loop\n",
    "        # Performs training using mini-batches\n",
    "        loss = self._mini_batch(validation=False)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        # VALIDATION\n",
    "        # no gradients in validation!\n",
    "        with torch.no_grad():\n",
    "            # Performs evaluation using mini-batches\n",
    "            val_loss = self._mini_batch(validation=True)\n",
    "            self.val_losses.append(val_loss)\n",
    "\n",
    "        # If a SummaryWriter has been set...\n",
    "        if self.writer:\n",
    "            scalars = {'training': loss}\n",
    "            if val_loss is not None:\n",
    "                scalars.update({'validation': val_loss})\n",
    "            # Records both losses for each epoch under the main tag \"loss\"\n",
    "            self.writer.add_scalars(main_tag='loss',\n",
    "                                    tag_scalar_dict=scalars,\n",
    "                                    global_step=epoch)\n",
    "\n",
    "    if self.writer:\n",
    "        # Flushes the writer\n",
    "        self.writer.flush()\n",
    "        \n",
    "setattr(StepByStep, 'train', train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(self, filename):\n",
    "    # Builds dictionary with all elements for resuming training\n",
    "    checkpoint = {'epoch': self.total_epochs,\n",
    "                  'model_state_dict': self.model.state_dict(),\n",
    "                  'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                  'loss': self.losses,\n",
    "                  'val_loss': self.val_losses}\n",
    "\n",
    "    torch.save(checkpoint, filename)\n",
    "    \n",
    "setattr(StepByStep, 'save_checkpoint', save_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(self, filename):\n",
    "    # Loads dictionary\n",
    "    checkpoint = torch.load(filename)\n",
    "\n",
    "    # Restore state for model and optimizer\n",
    "    self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    self.total_epochs = checkpoint['epoch']\n",
    "    self.losses = checkpoint['loss']\n",
    "    self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "    self.model.train() # always use TRAIN for resuming training   \n",
    "    \n",
    "setattr(StepByStep, 'load_checkpoint', load_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Set is to evaluation mode for predictions\n",
    "    self.model.eval() \n",
    "    # Takes aNumpy input and make it a float tensor\n",
    "    x_tensor = torch.as_tensor(x).float()\n",
    "    # Send input to device and uses model for prediction\n",
    "    y_hat_tensor = self.model(x_tensor.to(self.device))\n",
    "    # Set it back to train mode\n",
    "    self.model.train()\n",
    "    # Detaches it, brings it to CPU and back to Numpy\n",
    "    return y_hat_tensor.detach().cpu().numpy()\n",
    "\n",
    "setattr(StepByStep, 'predict', predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(self):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.plot(self.losses, label='Training Loss', c='b')\n",
    "    if self.val_loader:\n",
    "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "setattr(StepByStep, 'plot_losses', plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_graph(self):\n",
    "    if self.train_loader and self.writer:\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        x_sample, y_sample = next(iter(self.train_loader))\n",
    "        self.writer.add_graph(self.model, x_sample.to(self.device))\n",
    "    \n",
    "setattr(StepByStep, 'add_graph', add_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load stepbystep/v0.py\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # These attributes are defined here, but since they are\n",
    "        # not informed at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step_fn = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step_fn = self._make_val_step_fn()\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to define a SummaryWriter to interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # This method does not need ARGS... it can refer to\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "        \n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Sets model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "            loss.backward()\n",
    "            # Step 4 - Updates parameters using gradients and the learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "\n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Sets model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # There is no need to compute Steps 3 and 4, \n",
    "            # since we don't update parameters during evaluation\n",
    "            return loss.item()\n",
    "\n",
    "        return perform_val_step_fn\n",
    "            \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch can be used with both loaders\n",
    "        # The argument `validation`defines which loader and \n",
    "        # corresponding step function is going to be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn = self.train_step_fn\n",
    "\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "            \n",
    "        # Once the data loader and step function, this is the \n",
    "        # same mini-batch loop we had before\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "        loss = np.mean(mini_batch_losses)\n",
    "        return loss\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False    \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the numbers of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # inner loop\n",
    "            # Performs training using mini-batches\n",
    "            loss = self._mini_batch(validation=False)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            # VALIDATION\n",
    "            # no gradients in validation!\n",
    "            with torch.no_grad():\n",
    "                # Performs evaluation using mini-batches\n",
    "                val_loss = self._mini_batch(validation=True)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "            # If a SummaryWriter has been set...\n",
    "            if self.writer:\n",
    "                scalars = {'training': loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses for each epoch under the main tag \"loss\"\n",
    "                self.writer.add_scalars(main_tag='loss',\n",
    "                                        tag_scalar_dict=scalars,\n",
    "                                        global_step=epoch)\n",
    "\n",
    "        if self.writer:\n",
    "            # Closes the writer\n",
    "            self.writer.close()\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {'epoch': self.total_epochs,\n",
    "                      'model_state_dict': self.model.state_dict(),\n",
    "                      'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                      'loss': self.losses,\n",
    "                      'val_loss': self.val_losses}\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.losses = checkpoint['loss']\n",
    "        self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "        self.model.train() # always use TRAIN for resuming training   \n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set is to evaluation mode for predictions\n",
    "        self.model.eval() \n",
    "        # Takes aNumpy input and make it a float tensor\n",
    "        x_tensor = torch.as_tensor(x).float()\n",
    "        # Send input to device and uses model for prediction\n",
    "        y_hat_tensor = self.model(x_tensor.to(self.device))\n",
    "        # Set it back to train mode\n",
    "        self.model.train()\n",
    "        # Detaches it, brings it to CPU and back to Numpy\n",
    "        return y_hat_tensor.detach().cpu().numpy()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.losses, label='Training Loss', c='b')\n",
    "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def add_graph(self):\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        if self.train_loader and self.writer:\n",
    "            x_sample, y_sample = next(iter(self.train_loader))\n",
    "            self.writer.add_graph(self.model, x_sample.to(self.device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classy Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Runs data generation - so we do not need to copy code here\n",
    "%run -i data_generation/simple_linear_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure1(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v4.py\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7645]])), ('0.bias', tensor([0.8300]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StepByStep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sbs \u001b[38;5;241m=\u001b[39m StepByStep(model, loss_fn, optimizer)\n\u001b[0;32m      2\u001b[0m sbs\u001b[38;5;241m.\u001b[39mset_loaders(train_loader, val_loader)\n\u001b[0;32m      3\u001b[0m sbs\u001b[38;5;241m.\u001b[39mset_tensorboard(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StepByStep' is not defined"
     ]
    }
   ],
   "source": [
    "sbs = StepByStep(model, loss_fn, optimizer)\n",
    "sbs.set_loaders(train_loader, val_loader)\n",
    "sbs.set_tensorboard('classy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sbs.model == model)\n",
    "print(sbs.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.train(n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9416]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()) # remember, model == sbs.model\n",
    "print(sbs.total_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.3],\n",
       "       [0.7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([.5, .3, .7]).reshape(-1, 1)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sbs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m sbs\u001b[38;5;241m.\u001b[39mpredict(new_data)\n\u001b[0;32m      2\u001b[0m predictions\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sbs' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = sbs.predict(new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.save_checkpoint('model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m\\\\BOSCH.COM\\DfsRB\\DfsDE\\DIV\\DC\\DC-MA\\AK\\EPO\\fuy3pk\\50_ADM\\21_BCC\\2023_Python_Beginner\\04_Beginner\\02_GitHub\\fypbjchina\\e02_PyTorchStepByStep\\model_configuration\\v4.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\u001b[39;00m\n\u001b[0;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Now we can create a model and send it at once to the device\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i model_configuration/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')), ('0.bias', tensor([0.8300], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sbs = StepByStep(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9414]], device='cuda:0')), ('0.bias', tensor([1.0233], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "new_sbs.load_checkpoint('model_checkpoint.pth')\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sbs.set_loaders(train_loader, val_loader)\n",
    "new_sbs.train(n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAEQCAYAAAC++cJdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3gU5doG8HtmW3oBEloKECDUQAAJIL0EDl16EfhEOoJgOYCCIhYQUQSliBQFRZQickQERZpKB0V6QBISpEkSIG3bzPfH6IZJAiRhs5Ny/66LS6fszLM7u5t73n3nHSE5OVkGEREREVEJIWpdABERERGRKzEAExEREVGJwgBMRERERCUKAzARERERlSgMwERERERUojAAExEREVGJwgBMRERERCUKAzARERERlSgMwBqKiYnRugRyEh7L4oPHsvjgsSw+eCyLl8JwPBmAiYiIiKhEYQAmIiIiohKFAZiIiIiIShQGYCIiIiIqUfRaF0BERETFh81mQ2pqqlO36ebmhtu3bzt1m6QdZx1PT09P6PX5i7IMwEREROQUNpsNd+/ehZ+fHwRBcNp2TSYT3NzcnLY90pYzjqcsy0hOToa3t3e+QjC7QGhAkoD0dODuXR2Skpz3BUFERKSl1NRUp4dfopwIggA/P798/9rAFmAX+/13Ea1aef8zFYmICDv27k3RtCYiIiJnYfglV3mU9xpbgF3MZFJPm83a1EFERERUUjEAu1jWAJyRwTNlIiIiIldiAHYxk0lWTVssGhVCREREBW748OEYOnRonh7Tvn17TJ8+vYAqIoB9gF0u60WPGRna1EFERESAn5/fA5cPHDgQS5Ysyff258+fD1mWH77iPdavX5/v4b3yYubMmdi9ezd2795d4PsqbBiAXcxozNoCzC4QREREWjl37pzj/7dv346JEyeq5t1vuC6r1QqDwfDQ7fv6+ua5Jn9//zw/hvKGXSBcjC3AREREhUfZsmUd//4Nq1nnnT9/Hn5+fti8eTM6d+6MsmXL4osvvsCNGzfw1FNPoWbNmihfvjyaNm2Kr776SrX9rF0g2rdvj2nTpmHGjBmoVKkSqlevjlmzZqlaibN2gahevTref/99jB8/HkFBQahduzaWLl2q2s/Zs2fRsWNHlC1bFlFRUdi1axdKly6NjRs35vu1uXXrFkaOHInQ0FCUL18evXr1QkxMjGN5YmIiRowYgbCwMJQtWxaRkZFYsWKFY/lHH32EyMhIBAYGIiwsDH379s13Lc7GFmAX0+sBUZQhSUrLr90uwGZT5hMRERVHfn55bwVVy9vjk5ML5q5xM2fOxBtvvIE6derAZDIhPT0djRo1wuTJk+Hj44MffvgBY8eORXBwMJo2bXrf7Xz++eeYMGECdu7ciaNHj2LMmDGIjIxEt27d7vuYDz74AC+//DKef/55bN26FVOnTkWTJk1Qv3592Gw2DBo0CJUrV8bOnTtx9+5dvPTSS5Ak6ZGe78iRI3H16lWsW7cOXl5emDlzJvr06YNDhw7BZDJh5syZuHjxIjZs2IBSpUohNjbWcYe3AwcOYPr06fjoo4/QqFEjJCcnY8+ePY9UjzMxdmnAzQ1IS8ucNpsZgImIiAq78ePHo2vXrtnm/WvkyJHYtWsXNm3a9MAAHBERgRdffBEAEBYWhlWrVmHv3r0PDMAdO3bE8OHDAQATJkzA0qVLsW/fPtSvXx/bt29HfHw8tm/fjoCAAABKWO/Ro0e+n+upU6fw008/YefOnWjYsCEA4OOPP0adOnWwefNm9O/fH/Hx8YiMjERkZCQAIDQ01PH4+Ph4eHt7o1OnTvDw8EBISAgiIiLyXY+zsQuEBrKOBGE2sx8wERFRYfdv0PuXzWbDnDlz0KxZM1SqVAkVK1bEjh07EB8f/8Dt1K5dWzVdrlw53Lx5M9+PiYmJQUhIiCP8AkCjRo0e+nwe5Pz58zAajWjQoIFjXqlSpVC9enVHH+kRI0Zg7dq1aNGiBV555RXs37/fsW6HDh0QEBCAiIgIjBo1Cl9++WW+79pWEBiANZB9LGBt6iAiIqLc8/DwUE3PmzcPy5cvx+TJk/G///0P+/btQ4cOHWC1Wh+4nawXzwmC8NDuCg96jCzLTr8D34NGrvh3X126dMEff/yBMWPG4Nq1a+jduzeee+45AMroGj///DM+/vhjlC9fHnPnzkVUVNRDg76r8Id3DWQNwBwLmIiIirNH7ZObkZFx39EYtHTgwAF07drVcXGXJEm4ePEigoODXVpH9erVcfnyZfz9998oU6YMAODo0aOPtM3w8HBYLBYcO3bM0QUiMTER58+fx7hx4xzrBQQEYPDgwRg8eDDWrl2LiRMnYt68eRBFEQaDAW3atEGbNm0wdepUVKlSBT/++COeeOKJR6rNGRiANeDmpj6rUu4Gl7cxAomIiEhbVatWxfbt23Ho0CH4+vpi0aJFuHbtmssDcMeOHREUFISxY8fi1VdfRUpKCl577TUIgvDQluGMjAycOHFCNc/Lywu1a9dGu3btMGHCBLz33nvw9PTEa6+9hoCAAPTs2RMAMGvWLDRq1Ag1atSA2WzG1q1bUa1aNYiiiC1btuDatWto0qQJ/Pz8sGvXLmRkZCA8PLzAXoe8YADWgNGonmYXCCIioqJn2rRpSEhIwBNPPAEPDw8MHToU3bt3x9WrV11ah16vd7S+tm3bFpUqVcLrr7+OAQMGwJT1Z+cszp49i5YtW6rmNWnSBN9//z2WLVuGqVOnol+/frBarWjatCk2bNgA4z9BRq/XY+bMmYiPj4ebmxuioqKwZs0aAEoXiKVLl+Ktt96C2WxG5cqVsXTpUjRo0AAZhSD4CMnJyWx6dLEOHTxx+HDmuceOHSlo3NiuYUX0qGJiYlCtWjWtyyAn4LEsPngsXe/27dv5uvHDwxTWLhCF2ZEjR9C+fXvs378fNWvW1LocFWcez/y+59gCrAFeBEdERETOtHnzZvj5+aFy5cqIjY3FtGnT0LBhw0IXfgsLBmANcBg0IiIicqY7d+7gtddew19//YVSpUqhZcuWePPNN7Uuq9BiANZA1hZgs1mbOoiIiKh4GDp0qOqWy/RgHAdYA2wBJiIiItIOA7AG2AeYiIiISDsMwBrIOg6wxcIWYCIiIiJXYQDWAMcBJiIiItIOA7AGsg59x1shExEREbkOA7AGsl4Ep9wKmYiIiIhcgQFYAxwGjYiIqPhZvXo1QkJC7judk/nz5yMyMtLp+6YHYwDWAIdBIyIiKhz69++PHj165Ljs3Llz8PPzw65du/K17b59++Lo0aOPUl42NpsNfn5++Pbbbwt8Xzl544030Lx58wLfT0FjANZA1j7AbAEmIiLSxtChQ7F3717ExcVlW7ZmzRoEBwejVatW+dq2u7s7AgICHrXEQrev4oABWAPsA0xERFQ4dOzYEYGBgfj8889V861WK7788ks8+eSTEEUlLk2fPh0NGzZEuXLlEBERgZkzZ8L8gFasnLolvPfee6hWrRqCgoIwduxYpKWlqZYfOXIEPXv2RJUqVRASEoL//Oc/qpbdiIgIAMCTTz4JPz8/R/eJnPa1fPly1K9fHwEBAWjQoAHWrFnjWPZvS/Lq1asxZMgQVKhQAfXr18eGDRty+9LlKCkpCaNGjUJoaCjKly+PJ554AufOnXMsT05Oxrhx4xAWFoayZcuifv36WLZsmarmBg0aIDAwEGFhYejduzckSXqkmnLCWyFrIGsfYI4CQURExZmvn9+jPT6P699OTs71unq9HgMHDsTatWsxdepUR9jdtm0bbt26hcGDBzvW9fb2xuLFi1GuXDmcPXsWkydPhpubG6ZOnZqrfa1fvx5z5szBO++8g8cffxwbN27Ehx9+iDJlyjjWSUlJwcCBA/H2228DAJYtW4Y+ffrg+PHj8PPzw08//YQaNWpg0aJFaN++PfT6nKPc5s2bMW3aNMyePRutW7fGjh07MGnSJJQrVw4dOnRwrPf2229j5syZeO2117Bq1SqMGzcOTZs2RcWKFXP9Gt5r9OjRiIuLwxdffAEfHx/MmjULvXv3xpEjR+Dm5oZZs2bhwoULWL9+PcqUKYPY2FgkJSUBUML/1KlTsXTpUjRu3BjJycnYu3dvvup4GLYAa4AtwERERIXHkCFDkJCQgN27dzvmffbZZ2jbti2CgoIc86ZMmYKoqCiEhoaiY8eOmDRpEjZu3Jjr/SxZsgRPPvkkhg0bhqpVq2LKlCmOFt1/tW7dGv3790d4eDjCw8Mxb948iKKInTt3AoAjLPv6+qJs2bIoXbp0jvv64IMPMGjQIIwYMQJVq1bFuHHj0Lt3b7z//vuq9QYOHIi+ffuiSpUqmDFjBgDgwIEDuX5O9zp37hx27NiBhQsXolmzZqhTpw6WLVuG5ORkx+sUHx+PunXrokGDBggJCUHLli0dfbDj4+Ph5eWFTp06ISQkBBEREXjmmWccJyXOxACsAY4CQUREVHiEhYWhWbNm+OyzzwAAV69exc6dOzFkyBDVeps2bULHjh1RvXp1VKxYETNmzEBCQkKu93P+/Hk89thjqnmNGzdWTd+4cQPPPvssGjZsiJCQEAQFBSExMTFP+/l3X1FRUap5TZo0UXVHAIA6deo4/t9oNKJ06dK4efNmnvb1r3PnzkGv16NRo0aOeX5+fqhRo4Zjv08//TQ2bdqE5s2bY8aMGfjll18c67Zr1w7ly5dHvXr1MGrUKHzxxRdISUnJVy0PwwCsAV4ER0REVLgMHToUW7duRVJSEtauXQt/f3907tzZsXz//v0YOXIkOnTogHXr1mHv3r146aWXYHFyP8ZRo0bhxIkTmD17NrZv3459+/ahfPny+dqPIGT/hTnrvKxdKARByHefW1mW77vs3/126tQJhw8fxvjx43Hjxg307dsXEydOBAD4+Phg3759WLFiBSpUqIB3330XUVFRuH79er7qeRAGYA0YjRwGjYiISo7bycmP9O/6tWt5Wj8/evToAZPJhC+//BKfffYZBgwYAIPB4Fh+8OBBBAcH44UXXkCDBg0QFhaGy5cv52kf1atXx5EjR1TzDh8+rJo+cOAARo8ejejoaNSsWRMeHh6qAKjT6aDT6WC32x+6r6xdGQ4cOIDw8PA81ZwXNWrUgM1mUz3H5ORknD17VrXfMmXKYODAgfjoo4/w/vvv47PPPoPVagWgBPLWrVtj5syZ+Pnnn3H79m3s2LHD6bXyIjgNZG0BzsjQpg4iIiJSuLu7o2/fvpgzZw6Sk5OzdX8ICwtDQkICNmzYgIYNG+KHH37A119/nad9jBkzBhMmTEC9evXQrFkzfP311/j9999VF8GFhYXhyy+/RGRkJFJSUjBjxgyY7uk7KQgCgoKCsHfvXjRp0gQmkwl+OVxkOHHiRIwYMQIRERFo3bo1tm/fjo0bN2LdunV5fGWyy8jIwIkTJ1TzPD09ER4ejo4dO+LZZ5/F/Pnz4e3tjVmzZsHPzw+9evUCoIwjXKdOHdStWxdWqxXffvstwsLCYDAYsHXrVsTHx6NZs2bw8/PDnj17kJaWViChnS3AGuCNMIiIiAqfIUOGIDk5GVFRUdlCV7du3TBu3DhMmTIFLVq0wM8//4xp06blafv9+vXDCy+8gFmzZqFVq1aIiYnB6NGjVessXrwYt2/fRsuWLTFixAg89dRT2UZkePPNN7Fr1y7Url0bbdq0yXFfPXr0wOzZs/HBBx+gSZMmWL58OebPn68aASK/Lly4gJYtW6r+/fs8li5dioiICPTv3x8dOnSAxWLBxo0b4fZP65/BYMCbb76J5s2bo1OnTjCbzVi7di0Apb/w//73P/To0QONGzfGkiVLsGjRomz9pJ1BSE5Ovn+HDSoQMTEiHnvM2zEdFmbH0aMF08mbXCMmJgbVqlXTugxyAh7L4oPH0vVu374NX9+8Dlr2cBkZGY4ARUWfM49nft9zbAHWAFuAiYiIiLTDAKwBjgJBREREpB0GYA1wFAgiIiIi7TAAa4AtwERERETaYQDWgNGonjabBTxg7GgiIiIiciIGYA2IYk7dIDQqhoiIyIkedDcwImd6lPcaA7BG2A2CiIiKG09PTyQnJzMEU4GTZRnJycnw9PTM1+N5JziNKC3AmRe/KRfC8QuDiIiKLr1eD29vb9y5c8ep271z5w58fHycuk3SjrOOp7e3N/T6/EVZBmCN8HbIRERUHOn1eqffDOPGjRsIDg526jZJO4XheLILhEay3gzDYuFQaERERESuwACsEZNJPc0WYCIiIiLXYADWCG+HTERERKQNBmCNcBQIIiIiIm0wAGskp5thEBEREVHBYwDWiJubugsE+wATERERuQYDsEaytgBbLNrUQURERFTSMABrJHsLMLtAEBEREbkCA7BGsg6DxovgiIiIiFyDAVgjHAaNiIiISBsMwBrhjTCIiIiItMEArJGsfYB5K2QiIiIi12AA1kjWUSDYAkxERETkGiUiAA8YMAChoaEYOnSo1qU4ZG0BZh9gIiIiItcoEQF43LhxWLp0qdZlqGS/E5w2dRARERGVNCUiALds2RJeXl5al6Hi5qaeZgAmIiIicg1NA/Avv/yCAQMGoGbNmvDz88Pnn3+ebZ3ly5cjIiICZcuWRatWrfDrr79qUKnzZR0GjTfCICIiInINvZY7T01NRa1atTBw4ECMGTMm2/JNmzZh6tSpePfdd9GkSRMsX74cffv2xYEDBxAcHAwAaNq0aY7bXr9+PYKCggq0/keRdRg03gqZiIiIyDU0DcDR0dGIjo4GoPTTzWrRokUYNGgQhg0bBgB45513sHPnTqxcuRKvvvoqAGD//v2uK9iJ2AJMREREpA1NA/CDWCwW/Pbbb5gwYYJqftu2bXHw4MEC229MTEyBbftet275AKjumE5MTHPZvqlg8PgVHzyWxQePZfHBY1m8FPTxrFat2gOXF9oAfOvWLdjtdgQEBKjmBwQE4MaNG3naVo8ePXDy5EmkpaWhVq1a+OSTT9C4ceMc133YC+Ysf/2lU03r9Z4u2zc5X0xMDI9fMcFjWXzwWBYfPJbFS2E4noU2AP9LENRdA2RZzjbvYb755htnluQUbm6AHlaUQiJuoCxHgSAiIiJykUI7DFrp0qWh0+mytfb+/fff2VqFixLhyhV4duqElk/WQAbc8DOaA2AfYCIiIiJXKbQB2Gg0on79+ti1a5dq/q5duxAVFaVRVY9O9vKC/sABuN28Ah0khOAyBEgcBYKIiIjIRTTtApGSkoI///wTACBJEhISEnDixAn4+/sjODgY48ePx+jRo9GwYUNERUVh5cqVuHbtGp566ikty340vr6QfXwg3LkDADDBgkDcQEZGoMaFEREREZUMmgbg48ePo1u3bo7p2bNnY/bs2Rg4cCCWLFmCXr16ITExEe+88w6uX7+OmjVr4quvvkJISIiGVT86KTgYulOnHNOhiEO8hQGYiIiIyBU0DcAtWrRAcnLyA9cZMWIERowY4aKKXEMKCsoWgGMyHtOwIiIiIqKSo9D2AS7OpCwt2CG4DLOZF8ERERERuQIDsAakf27j/K9QxHEYNCIiIiIXYQDWgBwUpJoORRzsdgE2m0YFEREREZUgDMAayNoCHILLAICMDC2qISIiIipZGIA1kFMXCADsB0xERETkAgzAGpADAyEbjY5pfyTDG3dw8yYDMBEREVFBYwDWgihCqlhRNSsElxEXx8NBREREVNCYuDQi59ANggGYiIiIqOAxcWkkpwvhGICJiIiICh4Tl0akHIZCi43l4SAiIiIqaExcGslpJAi2ABMREREVPCYujeTUBeLyZRGyrFFBRERERCWE0wLwtWvXcPbsWWdtrtjL6SK4O3cEJCdzKDQiIiKigpTnALxq1SqMHj1aNe/5559HrVq10KxZM7Ro0QK3bt1yWoHFVdZh0CrgLxhhZj9gIiIiogKW57T16aefwtvb2zG9d+9erFy5En369MErr7yCS5cuYd68eU4tslgymWAJDHRMipDREdsRF8cWYCIiIqKClOcAHBcXhxo1ajimN2/ejIoVK2Lp0qWYNGkSRo4ciW3btjm1yOIquXlz1fRwrOSFcEREREQFLM9py2KxwGAwOKZ37dqF9u3bQxSVTVWpUgXXrl1zXoXF2K1u3VTTXbAViWdualQNERERUcmQ5wAcGhqK3bt3AwCOHTuG2NhYtG3b1rH8xo0bqi4SdH+ptWsjuWJma7oBNtQ4sk7DioiIiIiKvzwH4OHDh2Pz5s1o1qwZevXqhYoVK6JDhw6O5QcOHFB1kaAHEAQkdn9SNatd3KfgWGhEREREBSfPAXjEiBFYsGABqlSpgv/85z/YuHEj3N3dAQBJSUm4efMm+vbt6/RCiyvj0/1gg84xXc16Gjh0VMOKiIiIiIo3fX4eNHToUAwdOjTbfH9/f0f3CMod76qB2GHojM7W/znmSUs+gRjVSMOqiIiIiIovpww5YDabsWHDBixfvhxXrlxxxiZLlO+DnlZN+3y3AUJSkkbVEBERERVveQ7AL7zwAprfM3yXzWZDx44dMWrUKLz44oto0qQJTp065dQii7srEdGIRahjWmfJgGHtWg0rIiIiIiq+8hyA9+zZg44dOzqmv/76a/z++++YN28efvjhB5QuXRrvvPOOU4ss7mrUFvAR1HfXM65cCUiSRhURERERFV95DsBXr15FaGhma+V3332HOnXqYPjw4WjUqBGGDx+OQ4cOObXI4q5dOxtW4GlYkDm+su7iRej27tWwKiIiIqLiKc8BWK/XIz09HQAgyzL27t2Ldu3aOZb7+fkhMTHReRWWAPXr22EvVQYb0Ec137R8uUYVERERERVfeQ7AtWrVwldffYXk5GR89tlnSEpKQvv27R3LL1++jDJlyji1yOJOpwPatrVhCcaq5uu3bYPAiwqJiIiInCrPAXjKlCk4deoUqlSpgmeffRZRUVGqi+K2b9+OBg0aOLXIkqBdOxt+RnP8gTqOeYLdDuOnn2pYFREREVHxk+dxgFu1aoU9e/Zg165d8Pb2Ru/evR3LkpKS0Lx5c3Tp0sWpRZYEbdvaAAhYgrFYjPGO+cbVq2F+8UXAYLj/g4mIiIgo1/J1I4zw8HCEh4dnm+/v74/Zs2c/clElUdmyMiIi7PjsxJN4G1PgjRQAgHjtGvTffQdbjx4aV0hERERUPOQrAAPApUuXsGPHDly+fBkAEBISgujoaFSuXNlpxZU07dtb8d4JH6zBEIzDEsd80/LlDMBERERETpKvAPzyyy9j6dKlkLKMU/vSSy9hzJgxePPNN51SXEnToYMN770HLMFYVQDW79sH8fffIdWrp2F1RERERMVDni+CW7RoERYvXozOnTtjx44diIuLQ1xcHHbs2IEuXbpgyZIlWLx4cUHUWuxFRdkRFCThJOpiD1qqlpkWLtSoKiIiIqLiJc8BePXq1YiOjsaaNWvw2GOPwcfHBz4+PnjsscewevVqtG/fHp988kkBlFr8iSLQt68FADAX/1UtM3z9NYTYWA2qIiIiIipe8hyAY2NjER0dfd/l0dHRiIuLe6SiSrJ+/awAgG34D06itmO+IEkwLVqkVVlERERExUaeA7C/vz9iYmLuu/zChQvw9/d/pKJKspo1JdSta4cMMVsrsPGzzyDcuqVRZURERETFQ54DcOfOnbFixQp8/vnnkGXZMV+WZaxduxYrV67kOMCPqF8/pRvEOgxAPIIc84X0dBjWrtWqLCIiIqJiIc8B+JVXXkF4eDgmTJiA6tWro1OnTujUqRPCw8Mxfvx4hIeHY8aMGQVRa4nRp48VgiDDCiM+wATVMuPq1cA9Jx5ERERElDd5DsB+fn746aefMGfOHNSrVw+JiYlITExEREQE5s6di7Vr1yIhIaEgai0xypeXER1tAwB8gv+DBZl3gdPFxED3669alUZERERU5OVrHGCj0YhRo0Zh1KhR2ZbNmzcPb731FhITEx+5uJJs4kQztm834CYC8Q16oC82OJYZP/0U6Y8/rmF1REREREVXnluAyTWaNbOjYUOlFfhjjFQtM2zZAiQna1EWERERUZHHAFxICYLSCgwAP6I9LqFS5rKMDBi/+EKjyoiIiIiKNgbgQqxrVxuqVFGGRFuOEaplxmXLALtdo8qIiIiIii4G4EJMpwNGjVKGRFuBp2GGMXPZpUvQb9umVWlERERERVauLoI7evRorjf4119/5bsYyq5/fytefdUN183lsBaD8BQ+cSwzLV4MW9eu2hVHREREVATlKgC3b98egiDkaoOyLOd6XXo4f38Z3btbsX69Ee9jkioA63/9Fbrjx2GPjNSuQCIiIqIiJlcBeNGiRQVdBz3AkCEWrF9vxAnUw49oh/bY6VhmXLwY6R9/rGF1REREREVLrgLwoEGDCroOeoDmze2oXNmOS5d0eA/PqQKw4euvkTFzJuSKFTWskIiIiKjo4EVwRYAoAkOGWAEA36MTziLcsUyw2WBkCzARERFRrjEAFxEDB1qg08mQIWI+JquWmVatAlJSNKqMiIiIqGhhAC4iypeXER2t3BluDYbgb5R2LBNu3+aNMYiIiIhyiQG4CBk6VBkTOB0eWIoxqmXGxYt5YwwiIiKiXGAALkI6dLChXDkJALAI42GBwbFMd+kS9N9+q1VpREREREUGA3ARotcDgwcrrcDXUB5roR6dwzR/PiDLWpRGREREVGQwABcxTz5pdfz/XPxXtUz/22/Q797t4oqIiIiIihYG4CKmcmUJrVsrIfgMauFr9FQtN733nhZlERERERUZDMBF0FNPWRz/PwdTVcv0+/ZBd/iwq0siIiIiKjIYgIugzp1tCAxULoY7hCj8hDaq5aa339aiLCIiIqIigQG4CDIYgCefzGwFfhMvq5f/+CN0hw65uiwiIiKiIoEBuIgaOtQCQVBGfPgJbbEXLVTLTbNna1EWERERUaHHAFxEVaoko1072z9TAl7BLNVyw65d0P36q+sLIyIiIirkGICLsPHjM7tB7EHrbH2B3dgKTERERJQNA3AR1rq1DRERmbc/fhWvqZbr9+2Dbu9eV5dFREREVKgxABdhggBMmmR2TP+MFvhR6KBax232bN4djoiIiOgeDPBSDngAACAASURBVMBFXPfuVlSqlNkKPEPO0gq8fz90e/a4uiwiIiKiQosBuIjT64FnnsnsC3wATbFD/x/VOm5vvslWYCIiIqJ/MAAXA4MHW1CmjOSYftmWpRX48GHot2xxdVlEREREhRIDcDHg7g6MHp3ZCnwEj+F7Uzf1Oq+8AmRkuLo0IiIiokKHAbiYGDHCAk/PzG4Ok8xzYRf1jmkxLg7Gjz7SojQiIiKiQoUBuJjw95cxdGhmK/A51MDn3mNU67jNmwfhxg1Xl0ZERERUqDAAFyPjx5uh12e2Ak++PRNmT3/HtHD3LkxvvaVFaURERESFBgNwMRIUJKNvX6tjOhGlscBnumod4+rVEE+dcnVpRERERIUGA3AxM2mSGYKQ2Qo8/eozuFu+qmNakCS4vfwyh0UjIiKiEosBuJgJD5fQtavNMW2FEW/4zlWtY9i9G/rt211dGhEREVGhwABcDD33nFk1PfdsT/xdr5VqntvUqUB6uivLIiIiIioUGICLochIO9q0sd4zR8ALwruQxczDrYuNhendd11fHBEREZHGGICLqSlT1K3An/7WELGdR6nmmRYsgHj+vCvLIiIiItIcA3Ax1aRJ1lZgYPSNNyCVLeuYFqxWuD/3HCBJWR9OREREVGwxABdjU6eqW4F/OFQax4a8rZqn//lnGJcvd2VZRERERJpiAC7GoqLsaNs2SyvwzkGwtmunmuc2cybEixddWRoRERGRZhiAi7mXX1a3Ah87bsA3XRZB9vFxzBPS0uA+bhxgt7u6PCIiIiKXYwAu5ho2tKNbN3Ur8EtLqiL1DfUtkfUHD8I0Vz1eMBEREVFxxABcAkyfngFRzLzzW0yMDgtuPwVrx46q9Uxz50K3Z4+ryyMiIiJyKQbgEiA8XMKgQepW4BmvuOPrLoshBQY65gmyDI9RoyDcuOHqEomIiIhchgG4hJg6NQOenpmtwLIsYMgLlXHgmRWQBcExX7x+HR7DhgEWixZlEhERERU4BuASIihIxooVadDpMkOwxSKgz5LOSJv8gmpd/f79cJsyxdUlEhEREbkEA3AJ0qmTDR9+mK6ad/WqiDWVp8PWqpVqvmnVKhg/+siV5RERERG5BANwCTNwoBUjR6qHRlv0kSdSV66CFBqqmu8+ZQoMa9e6sjwiIiKiAscAXAKNH29WjQpx8qQOe08FIHXtWsienqp13Z95BoZNm1xdIhEREVGBYQAugSpVktGli001b/FiE6TatZG2ahVkg8ExX5AkuI8eDd3Ro64uk4iIiKhAMACXUGPHqrtBbN+uxx9/iLBFRyNtxQrIOp1jmWC1wmPYMAiJia4uk4iIiMjpGIBLqKZN7ahfP7MVWJYFTJjgDpsNsHXvjvTFi1XriwkJcB85ksOjERERUZHHAFxCCQLw3/+qW4F/+02PRYuMAABr//4wjx2rWm7YuRNeHTpAPHfOZXUSERERORsDcAnWubMNPXuqW3TfessN588rb4uMWbNgi4pSLdf9/ju8WrWCcelSQJJcVisRERGRszAAl3Bz52agVKnMIGs2Cxg+3APp6QAMBqStWgUpJET1GCEjA+5Tp8Kjd28IV6+6uGIiIiKiR8MAXMIFBsqYMydDNe/kSR1eeskNACBXqICUPXtgeeKJbI817NoFr06dINy44ZJaiYiIiJyBAZjQt68VvXqpu0KsWmXC+vXKcGiyvz/SV65E2kcfQfbxUa0nxsXBY+BAIC3NZfUSERERPQoGYIIgAO+/n44qVeyq+RMmuOPwYZ1jJWv//rj788+wPf64aj390aPwGDkSyFC3JBMREREVRgzABADw8QFWrUqDyZR5h7iMDAGDBnkgNlZwzJNDQpC6eTOsbduqHm/YuhVebdtCPHvWZTUTERER5QcDMDnUqyfhvffSVfNu3hTRv78nkpPvmfnPxXH2WrVU6+pOn4ZX69YwrlwJyDKIiIiICiMGYFIZPNiK555Td2U4d06HYcM8YbXeM9PXF6lffgl75cqqdYWMDLg/9xw8hgyBkJTkgoqJiIiI8oYBmLKZPt2MJ55QXxS3Z48ezz/vrmrYlYODkbJ7Nyx9+2bbhuHbb+HVogV0R48WdLlEREREecIATNmIIrB4cToee8ymmr96tRELFxrVK/v6In3ZMqQtWQLZy0u9nYQEeHbqBK9mzeDVoAHcR46E8PffBV0+ERER0QMxAFOO3N2BtWvTEBqqvtvbq6+645tv9OqVBQHWgQORsmcPbPXrqxdZrdCdPg3dn3/CuH49PKOjIV66VNDlExEREd0XAzDdV0CAjK++SoWPj/qCttGjPfDjj/ps60thYUjdsQPmMWPuu03dn3/CMzoahrVrodxujoiIiMi1in0ATkhIQJcuXRAVFYXHH38cW7Zs0bqkIiU8XMKaNanQ69XDo/Xp44kXX3RDamqWBxiNyJgzB6mffgrZ1zfHbYo3b8Jj3Dh416wJ0+uvQ7h1qwCfAREREZFasQ/Aer0es2fPxsGDB7F582ZMmzYNabxrWZ60amXH/PnZW2s//tiEbt08kZKS/TG2Hj1w58QJpOzcibv79sHSr1+2dcTkZLi9+y68IyJgeuMNwGLJviEiIiIiJyv2AbhcuXKIiIgAAAQEBMDX1xe32OKYZ0OGWPHaa+kQRXV3iGPH9Pi///NQD5H2L19f2Bs2hFS3LtKXLkXGCy9AFoRsqwmpqXCbNw+eTzwBITGxgJ4BERERkULTAPzLL79gwIABqFmzJvz8/PD5559nW2f58uWIiIhA2bJl0apVK/z666/53t/x48dhs9kQFBT0KGWXWM8+a8F336WicmX1LZN//NGACRPccw7B/xJFmKdPR8rRozBPmADJ3z/bKvpffoFn27YwbNwI3L4N3eHD0G/d+vCL5pKT8eCdExEREWXSNACnpqaiVq1amDNnDtzd3bMt37RpE6ZOnYrnn38ee/fuRePGjdG3b1/Ex8c71mnatGmO/xISElTbSkxMxJgxY/DBBx9AyKEVknKnSRM79u5NQb166hC8bp0RHTp44vz5B7+lpCpVkPH667h78iTS33gDUmCgarkuNhYeTz8N39BQeHXoAM/Bg+EdGQnPDh1gmj8f+m+/hfjnn8rKt2/DY+hQ+FaqBO/ISOiOHHHqcyUiIqLiSUhOTi4U96ytWLEi5s6di8GDBzvmtWvXDrVr18bChQsd8xo0aIAePXrg1VdfzfW2zWYzevbsiWHDhmHAgAFOrftRxMTEoFq1alqXkS/XrwuIjvZCXJw68Lq5yVi2LA3du9vu80g14dYteAwZAn0eW/ZtjRtDSE6G7vx5xzzZxwcpW7ZAql8fkCTof/wRuoMHATc32OvWhb1BA8hZArdTSBJiLlxAterVnb/tksRmg/6nnyCXLg17w4aalVGUP5ekxmNZhFgsEOPjIQUHA0ZjtsU8lsVLYTiehTYAWywWlC9fHitWrEDPnj0d673wwgs4ffo0vvvuu1xtV5ZljBgxAlWrVsW0adMeun5MTEz+nkAJFBdnwrhx4bhxQ/1lJYoypk+PRbduuetrLVitCH73XQRu3PjINdl8fZHcsiU8Tp+Gx8WL2Zan1K2LpDZtkFa9OsyhobB7eEDW6yG5uwOCAMPNmyj3ySfwOnkSqbVr41aXLkitVQvI6VcDWUbgF1+gwrJlkA0GXH7xRSRFRz/yc4DNBo9z52CpWBE2P79H3x4AMT0d+qQkWMqXz/m5aEx3+zaqPfssvE6dAgBcHzAA8c89l71WWYbPoUMQ09Nxu2lTyCZTztu7cwfG69eRUakSZIMBgsUCz9OnYff0RHpR+SMqScpdafLDbof7hQvQpaTA7usLc/nykDw9nV6f/08/QXfnDhKjoyFluRFOUSVYrZBFEdDptC7FKdxiYxG0YAEEux23OnVCYqdOuXpfiamp8N+5E5KHB243bw7Jza3AajRevYpqkybB/c8/kRESggvz5iGjcuUC29/9iBkZMNy8CX1iIuyensioWtUp2zXFxqL0tm2w+fkhMToattKlnbLd/HCPiYH7hQu4/fjjsPv4aFaHKzwsYBfaAHz16lXUrFkTW7duxeOPP+5Y7+2338b69etxJJc/d+/fvx+dO3dG7dq1HfM++ugj1bRWCsMZ0KNKTBQwaZI7tmwxZFs2cqQZ/ftb8fXXBuzdq0edOnbMnZsOb++ctyWePQvjqlUwfPUVxKQkSCEhkEqXhv748QJ+Fkrrsb1OHeh++w1CllFCpIoVYY+IgBwQoNzJzmqFvX59iAkJMH7xhWrd9LfeglShAnQnT0L29VWeQ61akLIe59RU6M6fh+zhAalqVccfWyEhAZ79+0N36hRkT0+kL1wIa48e0G/bBvHSJVh794ZcsWIOT0CG7uefoTtxArZ27SDVqAEkJ8Nt3jzot2+HeOECBFmGvW5dpC9cCNlkgnHdOoixsUBKCuDtDcsTT8DWowd0R47AuGgRBFmGrVEj2Fq0UFrVc3zh5PwH6n9afJCWBo8xY6D7J/z+yzx6NKydO0NMTIStWTPIgYFwf/ZZGFevBgBIwcFIf+MN2Lp3V9VgWLMG7lOnQkhNhVSmDGwdOkC/cyfEGzcc282YPfu+IeC+n8uMDOh/+AGG//0PYnw8rD17wvL004D+nzGxJQm633+HcPUqpCpVlOOqzz5etkNaGvS7dgGyDLlCBUihoZBLl4YQHw+3V16B4fvvYa9dGxmzZ8P+2GMQz51Ttl2tWs7vAQCQZeh37IDb9OnQ3XMyL7u5wTJ8ODJefRX456RBSEiA8fPPAUGAZdgwyGXLAgDEU6dg2LAB+t27Ifv6IuOttyDVqgVYrRDPnIFUvTpgMMD96adh3LzZcSxS162D9KDvVbsdQnw85PLlHTU8CuHmTbiPHQvd8eOwPvEEMmbOBO4N4bKM2F9+QdXkZIiXL8PetCnskZEQrlyB24wZEK9cgb1hQ1g7doS9WTPAYID+m28c7x1Lv37ImDEDyGk4R0lSRq3JTShMTYV+zx7Ifn6wN2784PfEg8gydIcOQXf8OIS7dwGzGVL16rC1aKG8pjm9RrGx8GrfHuI9d+C01a8Py7PPwtquHXCfACT+9hs8hwxRPp8ApFKlYHnqKVieeQayvz9gtUL/3XfQHz0K8fRpQBRhGTsWtjZtHvwc0tMh/P035HLlAIPyN0NISoJnp07QnTvnWE0KDET6woUQz56FkJwMqUoVxHl6okLPnpnflTduQLd/P/THjkFISoKlf3/Y78kKuWa1Qr99O4yffgr9Tz9BsGd277P06YP0Dz/M3XEGlOtRdDo4/sjZ7TB++CHc3nwTwj+jHMkGA6zdu8MyfDjsDRrA8NVX0O/aBal6dZgnTIBgtcL07rvQ79kDZGQAggB7kybKReShoXl/fvcwfPUV3MeOhWC3QwoIQOqWLZBq1nTUqt+xA7qjRwGjEbKXF+y1a8PepMkDP6+6X36B6Z13IKSnw9q1K6yDBkHORcAvDPmn0Afg7777Ds2aNXOsN2fOHGzcuBGHDx/WqlSnKQxvAGeQZWD1agMmT3aHJD04DPXqZcHKlbm4AYbZnPmHOi4Ohu+/hxgTA92pU9Dv369a1V6zJnRnzuS7flewh4fD1qIFhDt3IF64AN2JExBsSjcR2d0d9rp1YWvRQgmlV66oHiuFhkKMi1PW9fJC2urVsLVtC+Gvv5TX5MIFGD/9FLoTJ5R1dDqkL1gA05Il2UIlAMiCAEHO+WNva9BAOQmQ1HcAtHbqhLQVKwBPT4jnz8P46acwbNoE4dYtSOHhsEdGwtquHWzR0YCbG4Rr16A7exbimTPKf8+ehfjXX5BCQ2Ht1g3ipUswrl2r/CHPBdnTE9aOHWHctCl7zc2aIX3OHEghIXCbMwempUsfuj3LsGHImD4dssGgBBxBAGw2iCdPIuHiRVTo3Blwd4dw4wb0O3bAsH079Lt2Qcgy5p+9bl1Yu3eHmJAA/Y4dEK9ezazZaIQcGKh06ahZE5YhQ5SgJQgQbt6EZ7du0J09q9qeFBoK4eZN1UmYLIqQqldXrSsFByuh7/nnHQFNPHsWbi+/DMPOnfd93vaICGS8/DKE69fhPn06hDt3lO0FBMD80kvKH+Msny+pVClkvPYa3GbPVo6hn5/yh/unn1TryV5eSFu0CLbu3SH++ScMX3wB8epVSGFhQEoKjP9O/xNubJ06AVBCmtsbb0C/dy/sderAMmwY7PXqQYyLg2CxQKpaFVJIiLpF1myGZ9eu0N/zd8BerRrSP/wQ9rp1Ydi4EaaFC1UnAQCQMW0aDF98AV1srPp1qVQJ1gEDYJo7V/Xel8qVg61tW8ienoCHB2Q3N+jOnIFu716IycmQypRR3v9168LeqBHsdepAKldOee9cuwbDli0wLVjgCKBSQACs3bvD2rOn8l54QCuzePIkDFu2QPbzg1y+PIzLl0P/yy85H9eaNWHt0gW21q0Bmw1Cejrg5ga3KVNU3cRUx8tggK1dO5ifeUYJjmYzdH/8Af3OnTDNnw/BbM72GCk4GGkffAD3adNy/M619OoFOSAA4qVLkGrUgHnyZECSYHrnHeUk9OJFCJIE2dcXlqFDYWvYEKYlS6A/ePC+r4PqeVaqhIzXXoN+zx4YP/lEdaxkQUDGu+/CMny4+nWMiYFp/nzoDh6ErUULZLz2muMzI1y+DM8BA6A7ffq++7Q1a4a01ashlymTfWFyMgzffAPDDz9Ad/y447tbCgpSTmbj4iAmJ99327LJpHqd7VWqQLBYIGa5hglQTmLN48fD2quXckKaU8PD3bvKe95uV06sPTwge3tDLl8eupMn4fmf/6j2J5Urh9TvvgMsFrhPnAj9oUPZ9+vuDnu9epAqVFDe1zdvQrh7V/lMyjKMX32lXt9ggFSpEuQyZSDcvg3h2jXA2xu2Vq1g7dEDtnbtABSO/FNoA7CzukAUZoXhDeBM//ufHk8/7QGL5cEheO3aVHTunLs+wjkRz52DcdUqiOfOwdqjB6xDh8Lt1Vdh+uAD1XqyKMLasydkPz/ojxxxBMSiTtbrIVWqBN2FCy7dry0qCrKvLww7dtx3HdnbGxBFCLdvu7Ay5Y8fBCFbcM/VY318YA8Lg+7iRUcglE0mSJUrZwuoj8peqxYsTz8Nw5o10P/22yNvTypfHpb/+z8lcG7YoGq90oq9bl2l5e4hI7NY/rkew7Bpk6N17H5kg0FpsZdlSFWrPjCwFBVSYKAyTGRYGGC1QrhxA/D2hjU6GrozZ2CaM8dlx1Py94eYlOT87QYEAJIE0YVDj1r694cUFATh9m2If/4J/e7dqu8Fe40aSF23DvDyUlqec/k9aq9SBVJYmNLabrFAjIuD7siRh77PC4IUGAhbq1bKv9atIZcpA9Pbb8O0aFGOnyXZzQ0wGh3fb1qx9OuH9GXLABSO/FNoAzCgXARXp04dLFiwwDGvYcOG6N69e54ugiusCsMbwNn27tVh7FgPXLly/z5m5ctL2L//LpzUvdVBvHAB4vnzyh8SQYCtVSvIlSo5lgvx8TBs3aqcqV+4APHyZeVs2GxWnxWXKQPL6NHQHT8O/Q8/PPQLTgoOBm7cgJhDiwnlja1ZM4hnzhTIH+OSRhYE2CMjIV6+rPoJnEome+XK0D1sSMkcyF5e2X75KChS6dIuCcuytzdkLy/VLzaOGipUULr73Lzp1H1K/v6QS5cukIYL2ds717+maSltxQpYe/cGUDjyj27q1Kkztdp5SkoKzp49i+vXr2PNmjWoVasWfHx8YLFY4OvrC29vb8yePRvlypWDm5sb3nnnHfz666/48MMP4Xuf2+wWJYmJiSitYWf4ghAaKmPECAsqVJBx5owOt28L0OlkyHJmq3BKioCdOw0IDJRw86aAmBgdPD1lPOo1NHKpUpCqVYNUv77SZzVrwvb1hb1RI9i6dYN12DBYJk6EefJkmF94Adb+/WGPioK1Sxekv/MO7G3bwtq7N8zPPgtrt26wP/YYbG3bwjJ4MGwdOig/icoybO3aIW3NGsTWqIFSv/8O4fZt5efIvn1hj4wEPD0hXLmSY5cDe6VKgF6frc8xAOVn9atXVcFcFgQ8qG39fsvt9erh7sGDsDdtCv2vvzq+KG3NmiFjyhRYBg+GGB8P8a+/HI+RKlSAedIkCLduOf0Pwb0kPz/l58KyZWHt1w/pixfD1qmT0lpvtcJeowaEpCRHdxFAaQFPX7AAsNmg+3dIvKzbrVgRqevXw9a8ufKz8+DBML/0EvQ7djzSH3OpbFlYBg9WWuBz+AlY9vSEvVEj5WfoXO7HXrUq5HLllOf5T0uV5OcH8zPPKD8Z/3O/cVkUIdWsqfys+JCWQdvjjyPts89g+e9/YRk6FGJsbI6t2bLJBEhStveNrVUr2OvXV/XLzInk5wfzhAnQHTx43241BU328cnx53oAkHQ62P8ZMSbriay1dWvYGzeGePq06vnLggBrnz4QY2Ly9YtCjjV6eSldg5xwkmxt0wbWXr2U95ksQ7h+/aGvvS0qCqk//ghr166At7fyuX7ISabs4YH0Dz9E+gcfQLx+Hbo//sheS6dOME+cqHx//NPH/mFkd3fV5/lf9nr1kLpzJ2SdDrrDhwF3d9iio2Ht0QOyv7/yWcjyPO2VK8P6xBPQnTuX4zbvR7BYsn0+rdHRSFuxAubXX4d1yBDoDh3KsSvCA5+bwaD8EnVPnbKbG6y9eiFt7VpYJk+GrVkzCGlpjusyZB8f2Jo3z3ZyYh4zBumLFsFerx50R486vgfu93zyQgoNve+vdNboaFh79lTWSUzMVbC2V60Ky4gREK5eve/7ShZFZLz/PvDPkLeFIf9o2gK8b98+dOvWLdv8gQMHYsmSJQCUG2EsWLAA169fR82aNfHWW2+pLoorygrDGVBBkmXH9VWYNcuE9967/4UEOp2MHj2sGDfOgkaNtP8ZN69iYmJQrUoV5YYcWS6YEBITlZbka9cglykDuWxZ2OvWVS46kmUIV69Cv2eP0kfuyhVY+/VTfta+cAGmhQsh6/WwDBsG3aVLcB89OvNiCr1e6ZtVuTKkqlVh7d0b+u+/h/uMGY59S+XLI2XnTsgVKigz0tOh378fUlCQcjHTv2w2GFesgGHrVtgjI5ExebJyApGcDM9+/bL1DbM1bgzLiBGwtWgB3enTSj/ZzZshXr+u1ObhAXt4OKQaNWCvWRNSjRqQypWDftcuGL7/HjAaYRk8GNYePR56QZR4+jQ8nn4aujNnHOHX+s8vRfodO+D28suOvp72WrVgjY5WLtbJoc+eEBsL9xdegO7kSSWkpqYq/SX/fb1Kl4bVYIDp2rXM5xoZCVvHjrB17Ah7vXqOi+d0v/wC/Y8/QrDZIJUtC6laNdhatnR8wePOHQiJiY4+2vqtW7MFKluDBkjdskW5eCs9XekbfuMGbC1aAH5+EBITYVi3DhBFWLt2hRwUBKSlwfTuuzAtWJDtj74UGor011+HrVs3dR9BWYZ++3YYtm51/Pphr1ULGW+9BTEuDu6TJ0OMj4ft8ceRMX067E2bApIE9zFjHH38ZB8fpM+bB92BAzBs3Qr5n7689shIiH/8AbdZs2D44YfMWoKCYPm//4Nw9SqEjAylC01wMNzHj1edbAHK+9T8/PMQT5+GYft25QKvypUBvR7iuXMQ73OHSNnbGyk//gjxwgUYP/kEupMnIV69CtnTE5b+/XGuZ0+EtmwJ3ZEj8Ojb1/HH2da0KVI3bgQ8PKA7cgTuEydCd/q0EvrmzIF16FAI168rwzPevQshLU05UU1Lg+zrC3vz5rDXrg0xIQHiyZPQHz0K3bFjEBISIF67BpjNkAMDIVWsqJw4jx0L2dNTef9//TUM27bl6udoqUwZ2Nq3hxgXB6lCBViGDoW9VSvVOkJSEvTffads86+/AE9PJWSmpQHp6Uq/71dfVTcIyDJ0v/4K08KFyusNJaDIFSrAFhUFe/PmsHbpkjlspCwr3czuGZLUPGGC0p9WFAGrFcbVq6E7cgRSaChgscD04YeZ31UmE8z//S/MI0cCBgMM69fDsHUrhPR05UKrxx6DtXv3zAsEbTZlu/dcqHplyxZUX7AA+qNHIXt4wPz88zA/8wxgMkF38CA8+ve/b39be40akEJDHc81K2ubNkj78kv18GsZGTC9/z4MX3/9wJMhe1gYrH37wtqpk9I3V5aV9VNSIAUHK10mcrjgVrhxA2JMjPKd4uUF/TffKK+v3Q7z5Mmw9eiRufKdOzB++SX0O3dC/8svDwylUpkykCpVUv62pKVB+PtvVSOGNToaaatXw+3ll5XrMNLTlX67NWooDT69e2d+d8gyxEuXIFy+rHxmLRble9XDA+L58xAvXoRUubLS79rNTdlnYiKEa9eUC8Z9fCCVLQvduXMQz5yBZdw4Rx2FIf8Umi4QJVFheAO4SkYG0KaNF86cefjQQo0b2zBunBldu9ryfcG0q7nqWIp//gn9tm2QgoOVC15yuIrbuHQpTPPnQ6pQAemLF2de5Ztfd+/Cfdo06Ldtgz0iAuZJk2Bv2TL7RRh2O8Q//4RsMEAOCcn/EF45sdmgO3QIUoUKqm4tjv2eOQM5IMAxkkGuSRKEK1cgXrqk/IJQqxZiLlxAuChmjrhQrpxTnoKQkADjJ5/A+OmnEG/efPDFNbkgnj4N46pVgCRBqlRJGRGgdev8jbAgScrZatb3kyTBsHEjxIQEWPr1U48+kcMIILpff4Vh61ZIVarAMmhQ5snAPYTERBg+/xzCnTuQAwKU93KrVoCHx/3rS0tTWtZSUmDYsgX6778HZBkZ06dnH6EkJQXw9AQEQfW5FOLjYVy5ErK/PywjR6prkySIFy5A9veHHBCQq5fsvmRZ+feg97/ZDN3p0xBjYiDGxkJ2d4dcpgx0x47BsHkzhL//hq1LF6S/+27e39N5decOhKQk5STZkH00n3vpt2yBftcu2Dp0gK1zrESgHgAAHgpJREFU5weuK8bEKO9PWYZl+PDsI+HkUUxMDKpVrQohLk55TbK8t4Rr16D//nsId+5AMJshu7tDCg5WGgjq1AEAmObPV04c7zn5sDVpgtQNG/DAnyDT0pRW5itXlBMcnU4Z4adyZeVEzZVDS1qt0B07Bv2uXdDv2QPd4cOOE2HL0KFIf/119cglsgzh8mXojx2DbDLB1rFj5sWXjzKKzyMqDPmHAVhDheEN4Eo3bwp4/vmch0zLSbVqdkydakajRjbYbAIqVpTg5qY0sn7xhQHHjunQvbsNbdvm/4I6Zylpx7I4K/BjKUlK4ChVqlCOyVycFMnPpSwrLQY5nDyUZE47lhaL0i/+4kVAr1dOvopKS0tO7t6F7vffIZcrpwy9WEQUhs9mET7qVNQEBMhYvToNv/8uYtEiE06d0sHbW8bffwu4cCF7y3BMjA5PP53ZKuTuLqNPHyt++02HP/5Q1v/kExPGjjXj9dczivR3GJUgopircTKphBIEht+CZDQqQ+sVobD4QN7esDdvrnUVRRIjA7lcvXoSli3L7Hcpy8BPP+mxeLERO3fev3U4PV3AmjXZb5G5ZIkJ27bpERgow81NuR2zv7+Mbt2s6NLFxkY2IiIq0cxmpacTz60yMQCT5gQBaNfOhnbtbDh7VsQHH5iwbp0Bdnvuk2tsrA5ZxrbHl18aUbeuHYGBEs6eVUaaaNPGhscft+HuXQHJyQJKlZJRoYKEKlUkBAXJEAQgNRVIShJQrpzs9FZlsxmIjRVRqZLkjJthUQ5SU5Vjf+mSiD59LKhXzzlX8juTLAMHDuiwZ48elStL6N3byl8wKF/sdqW7cVE+0ZdlZRz5nTsNaNLEhn79rMXlTtR59scfIiZOdMeZMzoMGWLBW29lPKxr9kOtWmXEjBlusNmASZPM+O9/zU69RKOoYh9gDRWGPjCF1YULIt57z4Sff9ZDkoD0dODWLfUn1sdHxp07zvvWL1NGgq+vjD//FCHLAkqVkhAdbUNQkOTYj4+PjFKlZNSoIaFWLfv/t3fv4VHU5wLHv7O7ud825LIhhEQgN0IIMeH2RKICCuVw8NYqIGrrDR6enlY56iNUW2vtIyAVikdrT7UHb7RyiPCAFU2r0nKLBJUYuRMgJFySkCu5b3Zmzh8/s7AkkOgBkpj38zx5kszM7s7OO7/Zd2be32/RdVXbXFBwGi+vGHQd0tJ0UlNV0lVVpdE+YtWaNd781395U11tISTE5I47nIwfr2OxQEiIyahROiEhJtu32/jqK1UeMnKkTnS0gculUVGhsXevleJiC0FBJgMHGgQEqA7Thw5Z2LzZRlmZhfh4g5kznaSm6tTUaFgsMGyYwcCBJmfPQlmZhbIyjfJyCz4+JpmZOjExJg0NcPKkhaYmjZYWCA83iY83qK+Hd9/1Zt8+C2FhJtnZLoKDobRUo7LSQl2dRmsrpKbq3HCDq9NvV3U61ddmDxhgenS0bnf2LHzwgRd5eTZ8fEymTnWRne2itlajpkbDbjcJDzdxudTJSXW1mt7YqOHnZ+LvD2fPauzfb+Gll3woL/9mpAarya9/3UJ2tosdO9S+lJhoEBlpUF1tob4ehg41GD7cwGqFykqNPXuOk5QUR329xo4dNvbvV+974kQX3t4m//qXjcOHrTid6opKTIzByJHqOZubNZqboalJw+kEu93Ebjc5dMhKfr6VigoLvr4mx45ZOHTo3Cf8uHEu/vu/m4iJMWluVn1UbDY6bCvThCNHLBQVWYiKMkhONigv1/jsMxv19RpJSTp+frB6tRe5uV44HAZ33dXG7be3ERxs4uNzrv+LywUHD6rtlJho4OUF9fVQVGSlsRFaW1W8UlJ0fHzUdj92zEJbm3p/27db2brVhq7D9de7uPXWNtraNEpLLZSWqt+BgSY33+xy7+eg2vIXX1hpadGIjjY4dszC//6vN0eOWBg40ODf/72N5GSDhgaNhgYV19ZWjdhYg8REHV9fqK/X2L1bnUCUl2skJRlcf70LqxVOndLw94dRo3ROnDjG3r0J5OfbqK1Vz+frCw6HQXS0SVqazrXX6gwebODnB2VlGoWFVgoLrXz1lRrGcdQonTvuaCMhQae1VcPX1yQgoOM+3N7OrVb1d1GRhZISCxERBkOGqP1t3z4LLhdce61ObKzZ4fF79ljYtk2148GDDZKTdfz9VaxCQkyGDTPc+0Rxscby5b7k5HgRHGwya5aTn/zEyTXXmO595dAhC5s2efHxxzbq6jQGDzaIilLbtrFRIyVF5557nFitsH69F6dOWUhMNMjIcFFebuHQIQsWC8TGGsTGGsTFGQQGqv2msNBKSYmFU6csBASYTJ/eRlaW2ghlZRonT1o4fVrD1xfS03UiIjpPNRoa4JFH/HjvvXM7e3q6i/vua+P4cQtWq2p7EREHSE7u+HnpcsGBAxY+/dTGl19acbk0vL1NHA6TrCwXEybohIaq125qgi+/tFJaaqG8XKOuTsPp1HC5ICjIJCRELdfSohEcbDJhgouQEJM33vDmk09sxMSY/Nu/tXHTTS7Cw02Pk46zZ6G01EJrq4bFYhIUBEOGGO2DZHDokAXDUHF0uTRKSzXOntUYNswgMdFA12HdOi/+8z/9aG4+98Q339zGm2824e8P+/ZZWLXKm5IStX8kJho4HAahoSYxMSZxcQZNTbBli43iYrVMQYG1wwhMU6e28dBDThobYe9eK/v3W/H3N5k82cWoUTq7d1s5ftxCbKzBpEkugoPV56I69liprtZITtaZMsWFYcCePVZMU7U5h6N9G6rX8vbuvD9ob8h/JAHuQb1hB+grXC7YtMnGmjXeNDfD3LlOMjN1/uM//MjN/X+eHl8B3t4mbW14jH/cHTabOjheCVaredGr6kFBJvX1HecNGGDQ1qZ1Ou9ir5GYaDBwoEooT59WyXZlpToC+viopCMqSp281NVBXZ3GqVPqg6OnBASYmKZK7HoTf3+V+AcGqg/b8vJz2xJA08xvvY8NHGgQGWlSVGShsVE91tfXJDLSpKSk4yeVt7c66Ssr++6XjAYOVHdZvLxMdu60eXzA9xa+viYtLd1br9BQdULp49MeF5XsmaZKcJxOrct9KTLSwGZTJwQtLVq3tonNZhIdrfbV06e1To8VAwcaDBpkcPiwSuC7omntCXP32/jFjiNxcQa1tVqnrxsdbWC3m/j7m/j5qX27oUGjqMjiPmG9lLAwJ4MHq4S8qUm9xtmzmnsfvpRBg1SiuGePtctvKu2ugADVNtva1Nj2nV2MCQ42SUjQ2b/fesn9wcfHxOm8eAxiYtT6f/HFpW8T+fqa6Dq0tfVc+4qMNGhs9IxLSIhJYqLOgw86mTVLjcfdG/IfSYB7UG/YAb4PTp1SV0dbWtSVy8ZGjZwcL9av7+RSoxBCCCGuuqVLm5k3T40N3RvyH6k6E31edLS6KnK+6dNdLFzYys6dVnx91e35I0cs5OZ6ceqURliYujVdWalu1e7bd+4MXdPULfXuXFkQvZOfn4mXF5e1ROZys9nU1fJ9+/ppsaMQF4iIMDhzRopTfXxMBg82Oh0d6bsaMED1cyks7LnjTVJS7/qSK0mAxfdWUpJBUtK5DlApKQYzZnQ+ZrDLBYcPW2hp0UhIUDWPeXlW8vJU3WhwsLrVefasxokTFvbsUbVQfn4mEREmAQGNXHONL83NmrvWE9StUl9fVQMbGmpyxx1tPPywk127rHz8sarb1HXVMa799tygQQYTJ7poalK1VQ0NqqYtIEAdQBITVa3p6dMabW2qVjQoyGT8eJ34eIO//c3Gxx970damXrO5WdV11terelmHQ92+jYw0KS9XtZStrRo2m0lMjEFIiErODh+2uhPIyEiDOXOcVFZa+OILdQCNiTGIilIjbjQ1wb/+ZfOoaz2fpqmauEslpHFxBrff7qSqysLf/majpkbVSoeHq9uqVVUWbDZ1Oz40VP0OCDBpatJoalLfOBgRoeri7rvPidMJ8+b5s3OnjaAgkxtvdBEaanL4sKpbDgsz8fY2KSiwuuvLAwNNgoOd6LoXpqlOnEaPVidP7TXEY8fqZGW5sNvV7caDB63s3WuhuVkjIEDd3m1PwGtqVK1yaKjJ+PEuhg83cLlUh6XMTJ3wcJP/+R9vXnrJh+PHLWiaerxhqLrBzm41Bwaq2vBTpywcP67quEeP1hk0SN3irarSSE3VueeeNoqLLaxd60VpqardvfAWf0SEKlVpL2/QNFVnGhGharWPHLFw4oSa5+WlasKDgkysVhg82GDyZBcuF+TkeHHggJXQUPXBHRtrEBNj8PXXVjZt8upw+zcmRtWTlpWp6Tfc4GLaNBcFBVY2b7bhdKr3GRSk9m1Ng6NHVe2zpqnbz1FRJtdd5yIhwSA/30pBgRV/f1UCUFGhsXu3jcZGkzFjVF1xSorxzf6iShYOHrSwe7eVAwesnDmjygl8fExGjNBJS9NJSzPw9zd5/30vtm614XKpcpCGhs5LDy4UFqb2xTNnNI4fV3WyI0YYGAbs3m3ttNwiPNxg/HidlBSd4mJVc2mafFPbbOHkSc/kMCFBZ8GCVlwueOcdb3bvtnrc/g4ONhk92sX06S5SU3VOnLBQWanqW5uaNN5+24uCApUGpKerMdX37rVy6JCFyEiT4cNV7XZJidrXSkpUqVJEhEFGhk5Skqop3rHDxqZNNgxDc++jQ4aoUqjKSo2vv7Ze8ra8t7fJ3XerDl95eTZWrfLGalXvr6RE1TE3NHT+eE1Tx4OxY3UmTnQRFaWOjwUFqkb9wAGLRzuKi1M1zlFRJmFh58pYGhpUWYXFotZn3z4r27bZaGzUGD5c5yc/cXLmjEZurhdHjlg67NPe3ur4GRSk6rlLSy0epSAOh0FYmEldnYamqbIMf3+TPXus7qR/0CC1XZ94ooXYWINHH/VjwwYvj9KIzEwX992njsVHj1qoqdGoqlKlJO3HsWHDdMaOVfvQ4cMWEhIMVq5sZvBggxUrfNi1y4rFor73JC7OIDVVLfvhh15UVqqa+uRknS+/tPLll1Y0TdWBx8cbDBum2tHmzTZ277bh62uSmqpjmlBYeC7OXl4mFgsepW3nfx73BlIC0YN6wy0AcXmcH0vThLo69cVWnXX4upjWVnXVOTTUvOw9uk1T1Rr6+XXsLd7aCrW1KiE8fyQCXVedS0wTEhK6N2pFZaXGiROqptcwYOBA011zarOpcpWvvrLS3Kw6toWEqB+7XX0YnfcNnDidnl9q9l16u5um6qQYGmpetCe1aapOO97eMGCASVHR1W+XncXHNFXHmjNnLDQ3q/99fVWnvfY4NTerE6Du9hJ3OnF3ToqKUkmKpqm4VFdrDBlidOjgVVamasDj4oxvtT+3UydgFqqqVJ3k0KEGI0YYV3zUAtNU7TIxsetYmqbqAOjv3/V3Iuh6ey22Rlub6kAVEaFGk7HZVE27YdChk9T5WltVQuvlpU54fH3VEI5djXxQVweVlapjmL+/et3zX6OtTZ20lJVpxMWpTlGX6u3f3qnSZjPdnecuxTBUR7JvvmjPQ0WF5u7IGBtrerxuS4t6v+rbmdUJq+rAqhLDmBij086z7ZqbYfPmE0RFxaHr6gQzJMQkOFidJHXxpXscPao6vV1zjdGt99murU295wuPfaZ57uTWx0fFbsAAz/dsGGrblpaqUX/a29qF2p/Lz8/sdIiyykqNkydV7X90tOr4erH9qrJS7XuRkZcvrWttVb87O/63n8y377fNzaptqGO7mmcYcPKkxuHDViZOPDcsaW/IfyQB7kG9YQcQl4fE8vtDYvn9IbH8/pBYfr/0hnhKsY0QQgghhOhXJAEWQgghhBD9iiTAQgghhBCiX5EEWAghhBBC9CuSAAshhBBCiH5FRoEQQgghhBD9ilwBFkIIIYQQ/YokwEIIIYQQol+RBFgIIYQQQvQrkgALIYQQQoh+RRJgIYQQQgjRr0gC3ANef/110tLScDgc3HDDDezYsaOnV0l0YfHixdjtdo+fxMRE93zTNFm8eDHJyclERUUxffp09u/f34NrLNpt376dWbNmMXz4cOx2O6tXr/aY353Y1dbWMnfuXGJjY4mNjWXu3LnU1tZezbchvtFVPOfPn9+hrd50000ey7S2tvLEE08wdOhQoqOjmTVrFidPnryab6PfW758ORMnTmTw4MEMGzaMmTNnsm/fPo9lpG32Dd2JZW9sl5IAX2Xr1q1j4cKFPPbYY2zZsoWxY8dy5513Ulpa2tOrJrqQkJDAwYMH3T/nn7isXLmSV155haVLl/Lpp58SERHB7bffTn19fQ+usQBobGwkJSWFJUuW4Ofn12F+d2L30EMPUVhYyNq1a8nJyaGwsJB58+ZdzbchvtFVPAFuvPFGj7a6du1aj/mLFi3i/fff589//jObNm2ivr6emTNnouv61XgLAti2bRsPPvggubm5bNy4EZvNxm233UZNTY17GWmbfUN3Ygm9r13KOMBX2eTJkxkxYgQvvfSSe1pGRga33norzzzzTA+umbiUxYsXs3HjRvLy8jrMM02T5ORkHn74YR5//HEAmpubSUhI4LnnnuP++++/2qsrLmLQoEG88MILzJkzB+he7A4ePMi4ceP46KOPGD9+PAB5eXlMmzaNXbt2kZCQ0GPvp7+7MJ6grjRVV1ezZs2aTh9TV1dHfHw8r7zyCnfddRcAJ06cYOTIkeTk5DB58uSrsu7CU0NDA7GxsaxevZpp06ZJ2+zDLowl9M52KVeAryKn00lBQQGTJk3ymD5p0iR27tzZQ2sluqu4uJjhw4eTlpbGAw88QHFxMQDHjx+nvLzcI65+fn5kZWVJXHu57sQuPz+fwMBAxo0b515m/PjxBAQESHx7qby8POLj48nMzOTnP/85Z86ccc8rKCigra3NI+YxMTEkJSVJPHtQQ0MDhmFgt9sBaZt92YWxbNfb2qXtijyr6FRVVRW6rhMREeExPSIigoqKih5aK9Edo0eP5g9/+AMJCQlUVlaybNkypkyZwmeffUZ5eTlAp3E9ffp0T6yu6KbuxK6iooKwsDA0TXPP1zSN8PBwabe90E033cSMGTOIi4ujpKSE3/72t9xyyy3885//xMfHh4qKCqxWK2FhYR6Pk+Nwz1q4cCEjR45k7NixgLTNvuzCWELvbJeSAPeA8xsrqNuwF04TvcvNN9/s8f/o0aNJT0/nL3/5C2PGjAEkrn1ZV7HrLI4S397phz/8ofvvESNGkJ6ezsiRI8nNzeWWW2656OMknj3nF7/4BZ999hkfffQRVqvVY560zb7lYrHsje1SSiCuorCwMKxWa4ezmcrKyg5nuaJ3CwwMJDk5maNHj+JwOAAkrn1Qd2IXGRlJZWUlpnmuu4RpmlRVVUl8+4CBAwcSHR3N0aNHARVPXdepqqryWE7aa89YtGgR7733Hhs3buSaa65xT5e22fdcLJad6Q3tUhLgq8jb25v09HQ2b97sMX3z5s0eNUyi92tpaeHw4cM4HA7i4uJwOBwecW1paSEvL0/i2st1J3Zjx46loaGB/Px89zL5+fk0NjZKfPuAqqoqTp8+7U6o0tPT8fLy8oj5yZMn3R2qxNXz5JNPkpOTw8aNGz2GlQRpm33NpWLZmd7QLq0LFy789RV5ZtGpoKAgFi9eTFRUFL6+vixbtowdO3bw8ssvExIS0tOrJy7i6aefxtvbG8MwKCoq4oknnuDo0aOsWLECu92OruusWLGC+Ph4dF3nqaeeory8nN///vf4+Pj09Or3aw0NDRw4cIDy8nLefvttUlJSCA4Oxul0EhIS0mXswsPD+fzzz8nJySEtLY2TJ0+yYMECMjIyZLilHnCpeFqtVn7zm98QGBiIy+Xi66+/5mc/+xm6rrNs2TJ8fHzw9fWlrKyM1157jdTUVOrq6liwYAHBwcE8++yzWCxyXehqePzxx3n33Xd54403iImJobGxkcbGRkBdLNI0TdpmH9FVLBsaGnplu5Rh0HrA66+/zsqVKykvL2f48OE8//zzXHfddT29WuISHnjgAXbs2EFVVRXh4eGMHj2ap556iuTkZEDddluyZAlvvPEGtbW1ZGZm8rvf/Y6UlJQeXnOxdetWZsyY0WH67NmzefXVV7sVu5qaGp588kk+/PBDAKZNm8YLL7zQoZezuPIuFc/ly5czZ84cCgsLqaurw+FwkJ2dzVNPPUVMTIx72ZaWFn75y1+Sk5NDS0sL119/PS+++KLHMuLKuljbefLJJ1m0aBHQveOqtM2e11Usm5ube2W7lARYCCGEEEL0K3KvRwghhBBC9CuSAAshhBBCiH5FEmAhhBBCCNGvSAIshBBCCCH6FUmAhRBCCCFEvyIJsBBCCCGE6FckARZCCHFRdrudBQsW9PRqCCHEZSUJsBBC9KDVq1djt9sv+vPRRx/19CoKIcT3jq2nV0AIIQQsXLiQIUOGdJielpbWA2sjhBDfb5IACyFELzB58mTGjBnT06shhBD9gpRACCFEH9Bei7tu3TrGjRuHw+EgKyuL3NzcDsuWlpby8MMPM3ToUBwOBxMmTOCvf/1rh+VM0+S1115jwoQJREVFMXToUG677TZ27NjRYdl//OMfZGdn43A4yMjIICcnx2O+y+Vi2bJlZGZmup9rypQpbNiw4fJtBCGEuEzkCrAQQvQCZ8+epaqqqsP0sLAw9987d+5k/fr1zJs3j8DAQN58803mzJnDhg0buO666wCoqqriBz/4ATU1NcydO5eoqCjWrVvH/Pnzqa2tZf78+e7ne+SRR3jrrbe48cYbufvuuzFNk/z8fPLy8sjKynIvt2vXLj744APuv/9+7r33Xt566y3mzp3LyJEjSUpKAmDJkiW8+OKL3HvvvWRmZtLY2EhhYSGff/45t95665XabEII8Z1otbW1Zk+vhBBC9FerV6/mpz/96UXnnzhxgsDAQOx2OwC5ubmMGzcOgOrqajIyMkhMTOTvf/87AE8//TQvv/wyGzZs4IYbbgDA6XQybdo0Dhw4wL59+wgJCWHr1q3MmDGDH//4x6xcudLjNU3TRNM0QF15ttlsbN++3Z3sVlRUkJqayrx583juuecAyM7OJjo6mjVr1lzGrSOEEFeGXAEWQoheYOnSpe4E83x+fn7uv6+99lp38gswYMAA7rzzTl577TVqa2ux2+3k5uaSlpbmTn4BvL29mT9/Pg899BDbtm1j+vTpbNy4EVAJ84Xak9922dnZHusWGRlJQkICxcXF7mlBQUHs37+foqIi4uPjv/0GEEKIq0gSYCGE6AUyMjK67AQ3bNiwi04rLS3FbrdTUlLCjBkzOizXnsCWlJQAcOzYMSIiIoiIiOhy3QYPHtxhmt1up6amxv3/okWLuOeeexg9ejTJyclMmjSJH/3oR2RkZHT5/EIIcbVJJzghhOgjLrwyC6pcoTsuXO78MoeuWK3WLp8zOzubr776ildffZW0tDTeffddJk+ezPLly7v1GkIIcTVJAiyEEH1EUVFRh2lHjx4Fzl2ljY2N5dChQx2WO3z4sHs+wNChQ6moqODMmTOXbf3sdjuzZ8/mT3/6E3v37iUrK4ulS5ei6/plew0hhLgcJAEWQog+Yvfu3eTn57v/r66uZu3atYwZM8bdSW7q1KkUFhayZcsW93JtbW388Y9/xN/fnwkTJgBwyy23APD88893eJ3uXlU+X3V1tcf/fn5+JCUl0draSlNT07d+PiGEuJKkBlgIIXqBTz75xH0193zp6enu+t2UlBRmzpzJ3Llz3cOg1dfX86tf/cq9fPtYwbNnz2bevHk4HA7Wr1/Prl27eP755wkJCQFUycLdd9/NqlWrKC4uZsqUKYAa8mzEiBE89thj32r9x44dS1ZWFhkZGQwYMIA9e/bw1ltvMXXqVIKCgr7rZhFCiCtCEmAhhOgFlixZ0un05557zp0Ajxs3juzsbJYsWUJxcTHDhg3jnXfeITs72718WFgYubm5PPvss6xatYqmpibi4+N59dVXmT17tsdzv/zyy4wYMYK3336bZ555hsDAQEaNGuUeU/jbmD9/Ph9++CFbtmyhpaWFQYMG8eijj/Loo49+6+cSQogrTcYBFkKIPsBut3P//fezYsWKnl4VIYTo86QGWAghhBBC9CuSAAshhBBCiH5FEmAhhBBCCNGvSCc4IYToA2pra3t6FYQQ4ntDrgALIYQQQoh+RRJgIYQQQgjRr0gCLIQQQggh+hVJgIUQQgghRL8iCbAQQgghhOhXJAEWQgghhBD9yv8B2quUnGmqEjUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = new_sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9414]], device='cuda:0')), ('0.bias', tensor([1.0233], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(sbs.model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v4.py\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "sbs = StepByStep(model, loss_fn, optimizer)\n",
    "sbs.set_loaders(train_loader, val_loader)\n",
    "sbs.set_tensorboard('classy')\n",
    "sbs.train(n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9414]], device='cuda:0')), ('0.bias', tensor([1.0233], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
